package org.opentestsystem.rdw.admin.service.impl;

import com.amazonaws.services.s3.Headers;
import com.google.common.base.Charsets;
import com.google.common.collect.Ordering;
import org.apache.commons.codec.binary.Hex;
import org.apache.commons.codec.digest.DigestUtils;
import org.apache.commons.csv.CSVFormat;
import org.apache.commons.csv.CSVParser;
import org.apache.commons.csv.CSVRecord;
import org.apache.commons.io.input.BOMInputStream;
import org.opentestsystem.rdw.admin.model.CsvValidationResult;
import org.opentestsystem.rdw.admin.model.StudentGroupBatch;
import org.opentestsystem.rdw.admin.repository.StudentGroupBatchRepository;
import org.opentestsystem.rdw.admin.service.CsvValidationService;
import org.opentestsystem.rdw.admin.service.GroupsSource;
import org.opentestsystem.rdw.admin.service.LocationStrategy;
import org.opentestsystem.rdw.admin.service.StudentGroupBatchService;
import org.opentestsystem.rdw.archive.ArchiveService;
import org.opentestsystem.rdw.common.model.ImportStatus;
import org.opentestsystem.rdw.messaging.GroupMessage;
import org.opentestsystem.rdw.reporting.common.web.security.User;
import org.opentestsystem.rdw.security.PermissionScope;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.cloud.stream.annotation.EnableBinding;
import org.springframework.cloud.stream.messaging.Source;
import org.springframework.http.MediaType;
import org.springframework.stereotype.Service;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.io.Reader;
import java.security.DigestInputStream;
import java.security.MessageDigest;
import java.util.Collection;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Properties;
import java.util.stream.Collectors;

import static com.google.common.collect.Lists.newArrayList;
import static com.google.common.collect.Maps.newHashMap;
import static org.apache.commons.lang.StringEscapeUtils.escapeJava;
import static org.opentestsystem.rdw.admin.model.CsvValidationResult.failure;
import static org.opentestsystem.rdw.admin.security.AdminPermission.GroupWrite;

@Service
@EnableBinding(Source.class)
class DefaultStudentGroupBatchService implements StudentGroupBatchService {
    private static final Logger logger = LoggerFactory.getLogger(DefaultStudentGroupBatchService.class);

    private final StudentGroupBatchRepository repository;
    private final ArchiveService archiveService;
    private final CsvValidationService validationService;
    private final GroupsSource source;

    @Autowired
    public DefaultStudentGroupBatchService(final StudentGroupBatchRepository repository,
                                           final ArchiveService archiveService,
                                           final CsvValidationService validationService,
                                           final GroupsSource source) {
        this.repository = repository;
        this.archiveService = archiveService;
        this.validationService = validationService;
        this.source = source;
    }

    @Override
    public Iterable<StudentGroupBatch> findAllStudentGroupBatches(final User user) {
        return repository.findByCreator(user.getUsername());
    }

    @Override
    public StudentGroupBatch upload(final User user, final MultipartFile file) {
        logger.debug("Processing upload request: {}", file.getOriginalFilename());

        final PermissionScope permissionScope = user
                .getPermissionsById()
                .get(GroupWrite)
                .getScope();

        final StudentGroupBatch.Builder studentGroupBatchBuilder = StudentGroupBatch.builder()
                .creator(user.getUsername())
                .filename(file.getOriginalFilename());

        final MessageDigest messageDigest = DigestUtils.getMd5Digest();

        try {
            final List<CsvValidationResult> validationResults = newArrayList();
            final Map<String, String> fileProperties = newHashMap();
            fileProperties.put("username", user.getUsername());

            try (final DigestInputStream digestStream = new DigestInputStream(file.getInputStream(), messageDigest)) {
                validate(digestStream, permissionScope, validationResults, fileProperties);
            }

            final String digest = Hex.encodeHexString(messageDigest.digest()).toUpperCase();
            List<CsvValidationResult> failures = validationResults
                    .stream()
                    .filter(x -> !x.isOk())
                    .collect(Collectors.toList());

            if (failures.isEmpty()) {
                logger.debug("Validated request: {}", file.getOriginalFilename());
                archiveFile(file, digest, fileProperties);
                studentGroupBatchBuilder
                        .digest(digest)
                        .message(validationService.toSuccessMessage(validationResults))
                        .status(ImportStatus.ACCEPTED);
            } else {
                logger.info("Request failed validation: {}", file.getOriginalFilename());
                archiveFile(file, digest, fileProperties);
                studentGroupBatchBuilder
                        .digest(digest)
                        .message(validationService.toFailureMessage(failures))
                        .status(ImportStatus.BAD_DATA);
            }
        } catch (final Exception exception) {
            logger.warn("Upload request failed with exception: {}", file.getOriginalFilename(), exception);
            studentGroupBatchBuilder
                    .digest(Hex.encodeHexString(messageDigest.digest()).toUpperCase())
                    .message("Exception processing upload: " + exception.getMessage())
                    .status(ImportStatus.BAD_DATA);
        }

        final StudentGroupBatch batch = repository.create(studentGroupBatchBuilder.build());
        if (batch.getStatus().equals(ImportStatus.ACCEPTED)) {
            source.send(
                    new GroupMessage.Builder()
                            .digest(batch.getDigest())
                            .uploadId(batch.getId())
                            .build().toJson().getBytes(Charsets.UTF_8),
                    MediaType.APPLICATION_JSON.toString(),
                    batch.getId()
            );
        }

        return batch;
    }

    private void archiveFile(final MultipartFile file,
                             final String digest,
                             final Map<String, String> fileProperties) throws IOException {
        try (final InputStream fileStream = file.getInputStream()) {
            final String location = new LocationStrategy.GroupUploadContentLocationStrategy().location(digest);

            //Check if file already exists in ArchiveService
            if (archiveService.exists(location)) {
                logger.debug("Upload already exists in S3: {}", file.getOriginalFilename());
                return;
            }


            final Properties properties = new Properties();
            properties.putAll(fileProperties);
            properties.put(Headers.CONTENT_TYPE, file.getContentType());
            properties.put(Headers.CONTENT_LENGTH, file.getSize());
            properties.setProperty("filename", file.getOriginalFilename());

            archiveService.writeResource(location, fileStream, properties);

            logger.debug("Uploaded request: {}", file.getOriginalFilename());
        }
    }

    /**
     * Chunk the uploaded payload by school id. Perform basic validation.
     *
     * @param inputStream     The uploaded payload
     * @param permissionScope The user permissions
     * @param validationResults collection of validation results; this method adds to it
     * @param fileProperties  metadata to store with file
     */
    private void validate(final InputStream inputStream,
                          final PermissionScope permissionScope,
                          final Collection<CsvValidationResult> validationResults,
                          final Map<String, String> fileProperties) {

        try (final Reader reader = new InputStreamReader(new BOMInputStream(inputStream), Charsets.UTF_8)) {
            final CSVParser parser = CSVFormat.DEFAULT
                    .withFirstRecordAsHeader()
                    .withIgnoreHeaderCase()
                    .parse(reader);

            final Iterator<CSVRecord> recordIterator = parser.iterator();
            if (!recordIterator.hasNext()) {
                validationResults.add(failure(0, "Empty file"));
                return;
            }

            // enhance file properties with the newline sequence and field delimiter (hard-coded for now)
            // note that the sequences are escaped, e.g. "\\r\\n"
            fileProperties.put("newline", escapeJava(parser.getFirstEndOfLine()));
            fileProperties.put("delimiter", escapeJava(","));

            final List<String> orderedHeaders = newArrayList(parser.getHeaderMap().keySet());
            final Ordering<String> ordering = Ordering.natural().onResultOf(header -> parser.getHeaderMap().get(header));
            orderedHeaders.sort(ordering);

            validationResults.addAll(validationService.validateHeaders(orderedHeaders));
            validationResults.addAll(validationService.validateRecords(recordIterator, permissionScope));

        } catch (final IOException exception) {
            logger.warn("Problem reading uploaded file", exception);
            validationResults.add(failure(0, "Error reading file [" + exception.getMessage() + "]"));
        } catch (final IllegalArgumentException exception) {
            logger.warn("Problem parsing uploaded file", exception);
            validationResults.add(failure(0, "File does not appear to be a valid CSV with a header row"));
        }
    }
}
